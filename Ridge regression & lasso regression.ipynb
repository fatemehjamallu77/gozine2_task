{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, KFold\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "from numpy import cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:/Users/lenovo/Desktop/g2 task/heart.csv' )\n",
    "dataset=data.to_numpy()\n",
    "class_target=dataset[:,-1]\n",
    "class_instances=dataset[:,:-1]\n",
    "class_instances=stats.zscore(class_instances, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(class_instances,class_target, test_size = 0.3 ,random_state = 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "standarddev_train=np.std(X_train)\n",
    "averagetrain=np.average(X_train)\n",
    "X_train=(X_train - np.average(X_train)) / (np.std(X_train))\n",
    "X_test=(X_test - averagetrain) / standarddev_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso predict list\n",
      "[[0.76360943 0.19084147 0.29537977 0.54900856 0.45258558 0.60646431\n",
      "  0.63531354 0.20136595 0.56341025 0.61131406 0.64208471 0.45464502\n",
      "  0.54176307 0.7933636  0.48990129 0.52358563 0.24013998 0.65528658\n",
      "  0.27826924 0.58433825 0.35796963 0.19084147 0.63937462 0.76813944\n",
      "  0.21839481 0.13904603 0.68016618 0.56368947 0.61760262 0.29379879\n",
      "  0.23505345 0.29379879 0.44565128 0.37587591 0.10026273 0.35392591\n",
      "  0.57827159 0.03221149 0.58906411 0.59604544 0.47752418 0.63771026\n",
      "  0.36879654 0.34864572 0.63975893 0.31616194 0.71962837 0.45537905\n",
      "  0.63975893 0.76767439 0.64483649 0.52988148 0.58929308 0.55180525\n",
      "  0.55878975 0.44479823 0.56638491 0.5761973  0.41787315 0.66354044\n",
      "  0.37850067 0.88721798 0.61781967 0.4679098  0.15616583 0.68847904\n",
      "  0.24013998 0.72412331 0.57701617 0.14334512 0.77853052 0.57619413\n",
      "  0.68847904 0.52988148 0.53137199 0.15616583 0.53559842 0.37685553\n",
      "  0.4955814  0.61165645 0.77853052 0.5761973  0.27287079 0.32209395\n",
      "  0.52449842 0.77003816 0.55878975 0.69853162 0.63531354 0.64899292\n",
      "  0.72412331 0.70986523 0.57471994 0.35906582 0.48318183 0.28548275\n",
      "  0.2985861  0.26220366 0.37685553 0.55441749 0.7570285  0.14334512\n",
      "  0.70957579 0.34088253 0.53137199 0.39520177 0.52910942 0.17637469\n",
      "  0.6553251  0.14719891 0.29245608 0.41397152 0.50975019 0.56341025\n",
      "  0.48156867 0.53742229 0.44565128 0.70365572 0.72827974 0.5823661\n",
      "  0.27549869 0.24883551 0.44479823 0.5761973  0.27549869 0.6979161\n",
      "  0.43445275 0.64281727 0.70172112 0.61760262 0.4679098  0.37761837\n",
      "  0.64532031 0.75474004 0.61426726 0.64899292 0.60259297 0.61426726\n",
      "  0.68702778 0.41787315 0.20108989 0.70795577 0.37772586 0.28093833\n",
      "  0.30807999 0.65528658 0.54858543 0.61760262 0.52845414 0.7933636\n",
      "  0.67549175 0.48759604 0.63771026 0.27826924 0.26223268 0.55785648\n",
      "  0.6493665  0.60911952 0.59634001 0.48990129 0.63177263 0.68509539\n",
      "  0.77437409 0.54963551 0.70957579 0.70132192 0.58263361 0.60593299\n",
      "  0.69170538 0.20896673 0.63937462 0.7570285  0.50263956 0.41110587\n",
      "  0.3651505  0.33637468 0.67549175 0.62390773 0.47151998 0.69779518\n",
      "  0.64426338 0.41110587 0.70510478 0.65451549 0.78060874 0.54963551\n",
      "  0.32400587 0.45537905 0.36646761 0.16390927 0.75945299 0.36879654\n",
      "  0.61326573 0.15188891 0.54542155 0.52910942 0.32209395 0.49734263\n",
      "  0.22836229 0.73696619 0.73659261 0.58131674 0.57619413 0.64483649\n",
      "  0.64208471 0.53237209 0.55447941 0.57471994 0.31107541 0.28548275\n",
      "  0.56368947 0.67308774 0.60259297 0.57827159 0.28093833 0.35792066\n",
      "  0.55180525 0.72827974 0.24883551 0.36573967 0.52449842 0.66354044\n",
      "  0.6496721  0.29067925 0.55180525 0.27575815 0.31107541 0.67308774\n",
      "  0.34943854 0.65528658 0.26005008 0.6308318  0.43445275 0.15188891\n",
      "  0.64426338 0.48217785 0.65982004 0.3457935  0.50651678 0.30254769\n",
      "  0.50975019 0.58131674 0.46142031 0.67308774 0.63828726 0.47151998\n",
      "  0.63450441 0.37587591 0.60593299 0.63117001 0.29537977 0.39469426\n",
      "  0.27549869 0.26005008 0.64840738 0.24013998 0.62628471 0.61165645\n",
      "  0.49235092 0.40193049 0.74666912 0.61760262 0.65963273 0.23505345\n",
      "  0.65451549 0.12964308 0.49520267 0.30724136 0.6504595  0.35168524\n",
      "  0.64840738 0.10026273 0.67303995 0.63658262 0.6504595  0.77853052\n",
      "  0.39227338 0.70126292 0.13904603 0.75703627 0.35168524 0.80548834\n",
      "  0.79307804 0.63983627 0.68847904 0.5907499  0.41398396 0.34943854\n",
      "  0.68702778 0.61781967 0.50263956 0.63975893 0.4088128  0.68016618\n",
      "  0.39227338 0.72665973 0.33131987 0.61714049 0.51356765 0.6308318\n",
      "  0.39520177 0.71373222 0.41397152 0.29379879 0.57489017 0.5761973\n",
      "  0.10026273 0.78060874]]\n",
      "Ridge_predict list\n",
      "[[ 0.88381996 -0.14343094  0.02914628  0.61006524  0.35362391  0.83512673\n",
      "   0.66906711 -0.09993408  0.54586713  0.83202587  0.71623429  0.4409916\n",
      "   0.4283589   1.13814739  0.66391204  0.71192566 -0.03373778  0.83940261\n",
      "  -0.09177597  0.65106913  0.22560746 -0.14343094  0.90204425  1.13147958\n",
      "  -0.00317847 -0.15555007  0.76054672  0.50417724  0.89178777  0.02608066\n",
      "   0.02057622  0.02608066  0.27514351  0.16702477 -0.23428843  0.15511022\n",
      "   0.49169281 -0.3757176   0.63681327  0.54017436  0.41365316  0.74779687\n",
      "   0.23184022  0.10389539  0.80275257  0.10476116  1.02946158  0.38015586\n",
      "   0.80275257  1.02656147  0.81173102  0.69811276  0.60244662  0.70901722\n",
      "   0.67545476  0.35736984  0.62020177  0.57784773  0.46245477  0.79968411\n",
      "   0.20810049  1.17773502  0.68586164  0.52764227 -0.18725452  0.87099078\n",
      "  -0.03373778  0.90795204  0.66404408 -0.22606863  1.07495644  0.62234574\n",
      "   0.87099078  0.69811276  0.42174082 -0.18725452  0.64314816  0.45260937\n",
      "   0.53986374  0.50195932  1.07495644  0.57784773  0.10555623  0.07392471\n",
      "   0.53322003  1.07190788  0.67545476  0.92120944  0.66906711  0.74545653\n",
      "   0.90795204  0.73399101  0.70231728  0.15721479  0.25181366  0.01970263\n",
      "   0.23873873 -0.15893154  0.45260937  0.57190878  1.19904669 -0.22606863\n",
      "   0.80964412  0.00424455  0.42174082  0.38941889  0.49769138 -0.23363648\n",
      "   0.93584466 -0.17050091  0.15349841  0.30087706  0.5130238   0.54586713\n",
      "   0.65339016  0.54007377  0.27514351  0.74214447  0.85330858  0.66945063\n",
      "   0.04081803  0.11849224  0.35736984  0.57784773  0.04081803  0.86474075\n",
      "   0.32922713  0.88860864  1.04179503  0.89178777  0.52764227  0.19184469\n",
      "   0.76614776  1.08703009  0.68261388  0.74545653  0.72859406  0.68261388\n",
      "   1.0177362   0.46245477 -0.03288879  0.94611817  0.24329316  0.20849864\n",
      "   0.25613724  0.83940261  0.69820457  0.89178777  0.61008258  1.13814739\n",
      "   1.00052561  0.47422658  0.74779687 -0.09177597  0.06613245  0.60270931\n",
      "   0.93516649  0.69726823  0.73060183  0.66391204  0.44367969  0.81243726\n",
      "   1.12188225  0.7132979   0.80964412  1.00709168  0.72300724  0.66223448\n",
      "   0.73368188  0.00431089  0.90204425  1.19904669  0.27101128  0.29309158\n",
      "   0.25026582  0.13493361  1.00052561  0.59665149  0.31144346  0.77976647\n",
      "   0.68619953  0.29309158  0.90557364  0.7706844   1.13257705  0.7132979\n",
      "   0.177949    0.38015586  0.27925321 -0.16529155  0.89477499  0.23184022\n",
      "   0.79094749 -0.2377616   0.56664183  0.49769138  0.07392471  0.46875435\n",
      "  -0.08517094  1.0175574   0.94919644  0.54446173  0.62234574  0.81173102\n",
      "   0.71623429  0.5112669   0.5947578   0.70231728  0.14232587  0.01970263\n",
      "   0.50417724  0.73248556  0.65331088  0.49169281  0.20849864  0.16245228\n",
      "   0.70901722  0.85330858  0.11849224  0.12187535  0.53322003  0.79968411\n",
      "   0.7684063   0.07615348  0.70901722 -0.13831367  0.14232587  0.73248556\n",
      "   0.21229881  0.83940261  0.03496683  0.83202276  0.32922713 -0.2377616\n",
      "   0.68619953  0.41400745  0.80788333  0.29948681  0.55902873  0.02478335\n",
      "   0.5130238   0.54446173  0.56800458  0.73248556  0.71296939  0.31144346\n",
      "   0.88867095  0.16702477  0.66223448  0.707158    0.02914628  0.324871\n",
      "   0.04081803  0.03496683  0.96237437 -0.03373778  0.57246591  0.50195932\n",
      "   0.46061819  0.36328592  0.90961406  0.89178777  0.61680934  0.02057622\n",
      "   0.7706844  -0.19671906  0.62350552  0.04192619  0.64561192  0.11116069\n",
      "   0.96237437 -0.23428843  0.80083878  0.82437258  0.64561192  1.1332639\n",
      "   0.13723455  0.9138582  -0.15555007  1.1510549   0.11116069  1.06459018\n",
      "   1.28138262  0.7442789   0.87099078  0.78244201  0.14395649  0.21229881\n",
      "   1.0177362   0.68586164  0.27101128  0.80275257  0.1868396   0.76054672\n",
      "   0.13723455  0.96090492  0.29916405  0.60453212  0.58190044  0.83202276\n",
      "   0.38941889  0.81011251  0.30087706  0.02608066  0.62921103  0.57784773\n",
      "  -0.23428843  1.13257705]]\n",
      "Logistic_predict list\n",
      "[[1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1.\n",
      "  0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0.\n",
      "  1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1.\n",
      "  1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      "  0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0.\n",
      "  0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0.\n",
      "  1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      "  1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0.\n",
      "  1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0.\n",
      "  1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0.\n",
      "  1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 308)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lasso Regression\n",
    "alpha_value = 0.1  \n",
    "\n",
    "reg_lasso = linear_model.Lasso(alpha=alpha_value)\n",
    "reg_lasso = reg_lasso.fit(X_train, Y_train).predict(X_test)\n",
    "lasso_predict=reg_lasso.reshape(1,-1)\n",
    "print(\"lasso predict list\")\n",
    "print(lasso_predict)\n",
    "lasso_predict.shape\n",
    "\n",
    "#Ridge Regression\n",
    "reg_Ridge = linear_model.Ridge(alpha=.5)\n",
    "reg_Ridge = reg_Ridge.fit(X_train, Y_train).predict(X_test)\n",
    "Ridge_predict=reg_Ridge.reshape(1,-1)\n",
    "print(\"Ridge_predict list\")\n",
    "print(Ridge_predict)\n",
    "Ridge_predict.shape\n",
    "\n",
    "#LogisticRegression\n",
    "LogisticRegression = linear_model.LogisticRegression(penalty='l2')\n",
    "LogisticRegression = LogisticRegression.fit(X_train, Y_train).predict(X_test)\n",
    "Logistic_predict=LogisticRegression.reshape(1,-1)\n",
    "print(\"Logistic_predict list\")\n",
    "print(Logistic_predict)\n",
    "Logistic_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso regression to classification list\n",
      "[[1 0 0 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0\n",
      "  1 0 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1\n",
      "  1 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 1 0 1 0 1 0\n",
      "  1 0 0 0 1 1 0 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 0 0\n",
      "  0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 0 1\n",
      "  1 0 1 1 1 1 0 0 0 0 1 0 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0\n",
      "  1 1 0 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 0 0\n",
      "  0 0 1 0 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 0\n",
      "  1 1 1 1 0 1 0 1 0 1 1 1 0 1 0 0 1 1 0 1]]\n",
      "Ridge regression to classification list\n",
      "[[1 0 0 1 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0\n",
      "  0 0 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 0 1 1 0 1 1\n",
      "  1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0\n",
      "  1 0 0 0 1 1 1 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0\n",
      "  0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1\n",
      "  1 0 1 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0\n",
      "  1 1 0 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0\n",
      "  0 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 0\n",
      "  1 1 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "classificationlasso_list=[]\n",
    "\n",
    "classificationlasso_list = np.where(lasso_predict > 0.5, 1, 0)\n",
    "print(\"Lasso regression to classification list\")\n",
    "print(classificationlasso_list)\n",
    "\n",
    "\n",
    "classificationRidge_list=[]\n",
    "classificationRidge_list = np.where(Ridge_predict > 0.5, 1, 0)\n",
    "print(\"Ridge regression to classification list\")\n",
    "print(classificationRidge_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)  # Define number of folds for k-fold cross validation\n",
    "for train_index, test_index in kf.split(class_instances):\n",
    "    X_train_kfold, X_test_kfold = class_instances[train_index], class_instances[test_index]\n",
    "    Y_train_kfold, Y_test_kfold = class_target[train_index], class_target[test_index]\n",
    "    reg_lasso_kfold = linear_model.Lasso(alpha=alpha_value)\n",
    "    reg_lasso_kfold.fit(X_train_kfold, Y_train_kfold)\n",
    "    reg_lasso_predict_kfold = reg_lasso_kfold.predict(X_test_kfold)\n",
    "    \n",
    "    \n",
    "    reg_Ridge_kfold = linear_model.Ridge(alpha=.5)\n",
    "    reg_Ridge_kfold.fit(X_train_kfold, Y_train_kfold)\n",
    "    reg_Ridge_predict_kfold = reg_lasso_kfold.predict(X_test_kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " reg_lasso_predict_kfold predict list\n",
      "[0.27362526 0.33987506 0.31107474 0.5339687  0.19646449 0.79875432\n",
      " 0.72553541 0.61718131 0.65829863 0.20627132 0.55172812 0.38481917\n",
      " 0.58673213 0.0770323  0.3799899  0.49081307 0.63274403 0.68280275\n",
      " 0.53179852 0.54734069 0.26285302 0.59644885 0.5309308  0.75376056\n",
      " 0.41497741 0.27875416 0.59644885 0.19646449 0.79979213 0.41628669\n",
      " 0.57415499 0.60298973 0.41628669 0.17035008 0.71539133 0.6266445\n",
      " 0.61748913 0.57107773 0.61748913 0.40136745 0.54861558 0.73967219\n",
      " 0.76601217 0.42218198 0.75376056 0.82106538 0.77678122 0.65843414\n",
      " 0.68670768 0.65965652 0.72970137 0.78208251 0.73746626 0.59280949\n",
      " 0.75376056 0.18639012 0.27362526 0.77564589 0.35329981 0.63727737\n",
      " 0.47844203 0.62808654 0.27056769 0.54506601 0.26285302 0.29464406\n",
      " 0.18588002 0.39786513 0.35117663 0.22091837 0.28846189 0.52513638\n",
      " 0.20409569 0.51481585 0.40136745 0.51491293 0.52649766 0.57452892\n",
      " 0.53337808 0.53623052 0.54992731 0.53337808 0.33987506 0.56644079\n",
      " 0.66196833 0.22038999 0.63020899 0.64961762 0.16029221 0.35589956\n",
      " 0.62941481 0.59143849 0.32538229 0.31910965 0.39676243 0.49008174\n",
      " 0.30286786 0.77678122 0.67661678 0.51635268 0.46153584 0.30694676\n",
      " 0.65668515 0.5339687  0.6486479  0.27056769 0.35972149 0.72324171\n",
      " 0.20627132 0.18639012 0.30286786 0.59841935 0.61541507 0.51635268\n",
      " 0.72553541 0.68670768 0.59493671 0.73967219 0.37771752 0.70868079\n",
      " 0.4225267  0.78808365 0.63782771 0.50449087 0.3542184  0.68003402\n",
      " 0.74896866 0.73306479 0.26285302 0.47844203 0.17960947 0.51491293\n",
      " 0.79522013 0.51086343 0.58122587 0.43537029 0.63804532 0.62941481\n",
      " 0.67950718 0.63782771 0.78808365 0.51190056 0.38361169 0.4225267\n",
      " 0.77183934 0.64073374 0.15063966 0.66445497 0.28901902 0.68127022\n",
      " 0.56703598 0.68280275 0.90571277 0.62494387 0.56307742 0.46153584\n",
      " 0.35542268 0.71321413 0.57865623 0.291976   0.59280949 0.46153584\n",
      " 0.48525682 0.30659051 0.53623052 0.43537029 0.27719492 0.62808654\n",
      " 0.41497741 0.58763194 0.65965652 0.28956262 0.63097693 0.22975257\n",
      " 0.3182793  0.65668515 0.27938754 0.35329981 0.3799899  0.45630153\n",
      " 0.37905456 0.63020899 0.39676243 0.38361169 0.61541507 0.28846189\n",
      " 0.75204186 0.68003402 0.67433801 0.59841935 0.40136745 0.68847478\n",
      " 0.59415587 0.21454057 0.77183934 0.14557612 0.71539133 0.14248506\n",
      " 0.55777613 0.56299122 0.58086713 0.23060214 0.32369866 0.63097693\n",
      " 0.35329981]\n",
      "reg_Ridge_predict_kfold list\n",
      "[0.27362526 0.33987506 0.31107474 0.5339687  0.19646449 0.79875432\n",
      " 0.72553541 0.61718131 0.65829863 0.20627132 0.55172812 0.38481917\n",
      " 0.58673213 0.0770323  0.3799899  0.49081307 0.63274403 0.68280275\n",
      " 0.53179852 0.54734069 0.26285302 0.59644885 0.5309308  0.75376056\n",
      " 0.41497741 0.27875416 0.59644885 0.19646449 0.79979213 0.41628669\n",
      " 0.57415499 0.60298973 0.41628669 0.17035008 0.71539133 0.6266445\n",
      " 0.61748913 0.57107773 0.61748913 0.40136745 0.54861558 0.73967219\n",
      " 0.76601217 0.42218198 0.75376056 0.82106538 0.77678122 0.65843414\n",
      " 0.68670768 0.65965652 0.72970137 0.78208251 0.73746626 0.59280949\n",
      " 0.75376056 0.18639012 0.27362526 0.77564589 0.35329981 0.63727737\n",
      " 0.47844203 0.62808654 0.27056769 0.54506601 0.26285302 0.29464406\n",
      " 0.18588002 0.39786513 0.35117663 0.22091837 0.28846189 0.52513638\n",
      " 0.20409569 0.51481585 0.40136745 0.51491293 0.52649766 0.57452892\n",
      " 0.53337808 0.53623052 0.54992731 0.53337808 0.33987506 0.56644079\n",
      " 0.66196833 0.22038999 0.63020899 0.64961762 0.16029221 0.35589956\n",
      " 0.62941481 0.59143849 0.32538229 0.31910965 0.39676243 0.49008174\n",
      " 0.30286786 0.77678122 0.67661678 0.51635268 0.46153584 0.30694676\n",
      " 0.65668515 0.5339687  0.6486479  0.27056769 0.35972149 0.72324171\n",
      " 0.20627132 0.18639012 0.30286786 0.59841935 0.61541507 0.51635268\n",
      " 0.72553541 0.68670768 0.59493671 0.73967219 0.37771752 0.70868079\n",
      " 0.4225267  0.78808365 0.63782771 0.50449087 0.3542184  0.68003402\n",
      " 0.74896866 0.73306479 0.26285302 0.47844203 0.17960947 0.51491293\n",
      " 0.79522013 0.51086343 0.58122587 0.43537029 0.63804532 0.62941481\n",
      " 0.67950718 0.63782771 0.78808365 0.51190056 0.38361169 0.4225267\n",
      " 0.77183934 0.64073374 0.15063966 0.66445497 0.28901902 0.68127022\n",
      " 0.56703598 0.68280275 0.90571277 0.62494387 0.56307742 0.46153584\n",
      " 0.35542268 0.71321413 0.57865623 0.291976   0.59280949 0.46153584\n",
      " 0.48525682 0.30659051 0.53623052 0.43537029 0.27719492 0.62808654\n",
      " 0.41497741 0.58763194 0.65965652 0.28956262 0.63097693 0.22975257\n",
      " 0.3182793  0.65668515 0.27938754 0.35329981 0.3799899  0.45630153\n",
      " 0.37905456 0.63020899 0.39676243 0.38361169 0.61541507 0.28846189\n",
      " 0.75204186 0.68003402 0.67433801 0.59841935 0.40136745 0.68847478\n",
      " 0.59415587 0.21454057 0.77183934 0.14557612 0.71539133 0.14248506\n",
      " 0.55777613 0.56299122 0.58086713 0.23060214 0.32369866 0.63097693\n",
      " 0.35329981]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(205,)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\" reg_lasso_predict_kfold predict list\")\n",
    "print(reg_lasso_predict_kfold)\n",
    "reg_lasso_predict_kfold.shape\n",
    "\n",
    "print(\"reg_Ridge_predict_kfold list\")\n",
    "print(reg_Ridge_predict_kfold)\n",
    "reg_Ridge_predict_kfold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso regression to classificationlassokfold_list list\n",
      "[0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 1 1 1 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 1 1\n",
      " 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 0 0 1 1 1 0 0 1 0 0 0\n",
      " 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1\n",
      " 0 1 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 0 0 0 0 0 1 0 0 1\n",
      " 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 0 1 0]\n",
      "Ridge regression to classificationlassokfold_list list\n",
      "[0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 1 1 1 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 1 1\n",
      " 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 0 0 1 1 1 0 0 1 0 0 0\n",
      " 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1\n",
      " 0 1 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 0 0 0 0 0 1 0 0 1\n",
      " 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "classificationlassokfold_list=[]\n",
    "\n",
    "classificationlassokfold_list = np.where(reg_lasso_predict_kfold > 0.5, 1, 0)\n",
    "print(\"Lasso regression to classificationlassokfold_list list\")\n",
    "print(classificationlassokfold_list)\n",
    "\n",
    "\n",
    "classificationRidgekfold_list=[]\n",
    "classificationRidgekfold_list = np.where(reg_Ridge_predict_kfold > 0.5, 1, 0)\n",
    "print(\"Ridge regression to classificationlassokfold_list list\")\n",
    "print(classificationlassokfold_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lable list\n",
      "[[1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      "  0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0.\n",
      "  1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1.\n",
      "  1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.\n",
      "  0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1.\n",
      "  0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0.\n",
      "  0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0.\n",
      "  1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
      "  0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0.\n",
      "  1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0.\n",
      "  1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 308)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_Ytest=Y_test.reshape(1,-1)\n",
    "print(\"lable list\")\n",
    "print(re_Ytest)\n",
    "re_Ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.378\n",
      "RMSE: 0.400\n",
      "covariance\n",
      "[[0.25029612 0.06108231]\n",
      " [0.06108231 0.03188722]]\n",
      "Spearmans correlation: nan\n"
     ]
    }
   ],
   "source": [
    "    # Lasso regression MAE و RMSE\n",
    "    mae = mean_absolute_error(re_Ytest, lasso_predict)\n",
    "    rmse = np.sqrt(mean_squared_error(re_Ytest, lasso_predict))\n",
    "    print('MAE: %.3f' % mae)\n",
    "    print('RMSE: %.3f' % rmse)\n",
    "    \n",
    "    covariance = cov(re_Ytest, lasso_predict)\n",
    "    print('covariance')\n",
    "    print(covariance)\n",
    "    # ارزیابی همبستگی\n",
    "    corr, _ = spearmanr(re_Ytest, lasso_predict)\n",
    "    \n",
    "    print('Spearmans correlation: %.3f' % corr)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.291\n",
      "RMSE: 0.360\n",
      "covariance\n",
      "[[0.25029612 0.12764771]\n",
      " [0.12764771 0.13502075]]\n",
      "Spearmans correlation: nan\n"
     ]
    }
   ],
   "source": [
    "    # Ridge regression MAE و RMSE\n",
    "    mae = mean_absolute_error(re_Ytest, Ridge_predict)\n",
    "    rmse = np.sqrt(mean_squared_error(re_Ytest, Ridge_predict))\n",
    "    print('MAE: %.3f' % mae)\n",
    "    print('RMSE: %.3f' % rmse)\n",
    "    \n",
    "    covariance = cov(re_Ytest, Ridge_predict)\n",
    "    print('covariance')\n",
    "    print(covariance)\n",
    "    # ارزیابی همبستگی\n",
    "    corr, _ = spearmanr(re_Ytest, Ridge_predict)\n",
    "    \n",
    "    print('Spearmans correlation: %.3f' % corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.172\n",
      "RMSE: 0.415\n",
      "covariance\n",
      "[[0.25029612 0.16316257]\n",
      " [0.16316257 0.24738779]]\n",
      "Spearmans correlation: nan\n"
     ]
    }
   ],
   "source": [
    "    # logestic regression MAE و RMSE\n",
    "    mae = mean_absolute_error(re_Ytest, Logistic_predict)\n",
    "    rmse = np.sqrt(mean_squared_error(re_Ytest, Logistic_predict))\n",
    "    print('MAE: %.3f' % mae)\n",
    "    print('RMSE: %.3f' % rmse)\n",
    "    \n",
    "    covariance = cov(re_Ytest, Logistic_predict)\n",
    "    print('covariance')\n",
    "    print(covariance)\n",
    "    # ارزیابی همبستگی\n",
    "    corr, _ = spearmanr(re_Ytest, Logistic_predict)\n",
    "    \n",
    "    print('Spearmans correlation: %.3f' % corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
